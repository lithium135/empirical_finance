{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d1b88d-b36e-4f45-80f5-6eacc5d2c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import xlrd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num\n",
    "import datetime as dt\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "PATH = \"C:/Users/jackl/OneDrive/Documents/finance_research/japan_qe/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcb31e6-8655-407e-aa8e-b866b997d915",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_dates(date): \n",
    "    date = str(date)\n",
    "    if date=='0': \n",
    "        return math.nan\n",
    "    elif date.isnumeric()==True:\n",
    "        return pd.to_datetime(dt.datetime(*xlrd.xldate_as_tuple(int(date), 0)))\n",
    "    elif date=='nan' or date=='None': \n",
    "        return math.nan\n",
    "    else:\n",
    "        return pd.to_datetime(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e9667-2f0f-4739-b237-4566d75a9620",
   "metadata": {},
   "source": [
    "# Old Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be481afa-4c4c-427e-ab86-d18f30ce9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw files on dropbox: jackliextradropbox@gmail.com, note name change (c1, c2, c3, c4)\n",
    "files = ['ownership_pt1.pkl', 'ownership_pt2.pkl', 'ownership_pt3.pkl', 'ownership_pt4.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dfe6821-6564-48e5-9f88-6f632f19fce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish load: ownership_pt1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 1/4 [06:19<18:58, 379.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ownership_pt1.pkl\n",
      "Finish load: ownership_pt2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [13:08<13:13, 396.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ownership_pt2.pkl\n",
      "Finish load: ownership_pt3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [20:30<06:57, 417.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ownership_pt3.pkl\n",
      "Finish load: ownership_pt4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [26:47<00:00, 401.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ownership_pt4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_pickle(PATH+'raw_data/capital_iq/'+file)\n",
    "    print(\"Finish load:\", file)\n",
    "    \n",
    "    #change columns\n",
    "    df.columns = df.iloc[0]\n",
    "\n",
    "    #set nan types\n",
    "    df = df.astype(str)\n",
    "    df = df.replace(['None', '(Invalid Identifier)', 'nan', 'NaN'], math.nan)\n",
    "\n",
    "    #remove header rows\n",
    "    df = df[~df['ticker'].str.contains('ticker')]\n",
    "\n",
    "    #make sure holdings data is float\n",
    "    df['holdings'] = df['holdings'].astype(float)\n",
    "    df['pct'] = df['pct'].astype(float)\n",
    "\n",
    "    #throw away observations where both holdings and pct are NaN/0\n",
    "    df = df[~ ( (df['holdings'].isna()) & (df['pct'].isna()) )]\n",
    "    df = df[~ ( (df['holdings']==0) & (df['pct']==0) )]\n",
    "\n",
    "    #get dates\n",
    "    df['date'] = df['date'].apply(lambda x: clean_dates(x))\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['asof_date'] = pd.to_datetime(df['asof_date'])\n",
    "    \n",
    "    print('Done:', file)\n",
    "    file_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b640025-42cc-4a6a-9a2b-d60752f1f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020c143-567e-4a1f-80fe-f2872b696a83",
   "metadata": {},
   "source": [
    "# Missed Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2357799-2ca9-4af3-9236-d7ecb091cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(PATH+'raw_data/capital_iq/missed_ownership.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3357fe8f-ff0b-4ee4-90bd-14e8818a9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change columns\n",
    "df.columns = df.iloc[0]\n",
    "\n",
    "#set nan types\n",
    "df = df.astype(str)\n",
    "df = df.replace(['None', '(Invalid Identifier)', 'nan', 'NaN'], math.nan)\n",
    "\n",
    "#remove header rows\n",
    "df = df[~df['ticker'].str.contains('ticker')]\n",
    "\n",
    "#make sure holdings data is float\n",
    "df['holdings'] = df['holdings'].astype(float)\n",
    "df['pct'] = df['pct'].astype(float)\n",
    "\n",
    "#throw away observations where both holdings and pct are NaN/0\n",
    "df = df[~ ( (df['holdings'].isna()) & (df['pct'].isna()) )]\n",
    "df = df[~ ( (df['holdings']==0) & (df['pct']==0) )]\n",
    "\n",
    "#get dates\n",
    "df['date'] = df['date'].apply(lambda x: clean_dates(x))\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['asof_date'] = pd.to_datetime(df['asof_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3c22ab-471d-4143-8432-40e14c380333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_merged, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb239c26-8f7d-4019-bcab-aa73b3a28c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[ ~( (df_full['holdings']==0) & (df_full['pct'].isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cc756-6608-42d2-9e9c-bd37b4bc20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_pickle(PATH+'checkpoint_data/ownership_jan03.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
